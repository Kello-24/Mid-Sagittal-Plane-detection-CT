{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mid-Sagittal plane algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import center_of_mass\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from matplotlib.widgets import Slider\n",
    "import ipywidgets as widgets\n",
    "from matplotlib.lines import Line2D\n",
    "import time\n",
    "from scipy import ndimage\n",
    "import json\n",
    "import skimage\n",
    "from scipy.spatial import ConvexHull, distance\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patterns of structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "\n",
    "    # Improved \"gtvp\" pattern\n",
    "    \"image\": r\"image\",\n",
    "\n",
    "    \"gtvp\": r\"\\b(?:klin|vorschlag|pr[ae]?eop|v1)?[\\s._-]*gtv[\\s._-]*p[\\s._-]*t?[\\s._-]*\\d*(?:new|rimary|pr[ae]?eop|v1|xxgy|74\\.4|70|ptv1)?[\\s._-]*(gy)?[\\s._-]*(1a)?[\\s._-]*(1b)?\\b\",\n",
    "\n",
    "    # Exact match for \"body\" with optional numbers or symbols following it\n",
    "    \"body\": r\"(?:^body[\\s._-]*\\d?$|^skin[\\s._-]*\\d?$)\",\n",
    "\n",
    "    # Improved \"spinal cord\" pattern for clearer boundary matching, including \"myelon\" as an alternative\n",
    "    \"spinal cord\": r\"(?:spinal[\\s._-]*cord$|^myelon$|myelon[\\s+]*5mm|spinal[\\s._-]*canal)\",\n",
    "\n",
    "    # Matches strings starting with \"mandib\"\n",
    "    \"mandibula\": r\"^mandib\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_eight_characters(input_list):\n",
    "    \"\"\"\n",
    "    Check if each string in the list has 8 characters, and if not, add zeros at the beginning to make it 8 characters long.\n",
    "\n",
    "    Parameters:\n",
    "    input_list (list): A list of strings.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of strings with each string padded to 8 characters.\n",
    "    \"\"\"\n",
    "    return [s.zfill(8) for s in input_list]\n",
    "\n",
    "def load_nifti_file(file_path):\n",
    "    \"\"\"\n",
    "    Load a NIfTI file and return the image data.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the NIfTI file.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The image data.\n",
    "    \"\"\"\n",
    "    import nibabel as nib\n",
    "\n",
    "    nifti_img = nib.load(file_path)\n",
    "    img_data = nifti_img.get_fdata()\n",
    "    voxel_size = nifti_img.header.get_zooms()\n",
    "    \n",
    "    return img_data, voxel_size\n",
    "\n",
    "def open_gzip_file(gzip_file_path):\n",
    "    \"\"\"\n",
    "    Open a gzip file and return its content.\n",
    "\n",
    "    Parameters:\n",
    "    gzip_file_path (str): The path to the gzip file.\n",
    "\n",
    "    Returns:\n",
    "    bytes: The content of the gzip file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with gzip.open(gzip_file_path, 'rb') as f_in:\n",
    "            file_content = f_in.read()\n",
    "        return file_content\n",
    "    except Exception as e:\n",
    "        print(f'Error opening {gzip_file_path}: {e}')\n",
    "        return None\n",
    "    \n",
    "def get_image_and_voxel_size_from_gzip(gzip_file_path):\n",
    "    \"\"\"\n",
    "    Get the image array and voxel size from a gzipped NIfTI file.\n",
    "\n",
    "    Parameters:\n",
    "    gzip_file_path (str): Path to the gzipped NIfTI file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: The image array and voxel size.\n",
    "    \"\"\"\n",
    "\n",
    "    file_content = open_gzip_file(gzip_file_path)\n",
    "    if file_content is not None:\n",
    "        with open('temp_nifti.nii', 'wb') as temp_file:\n",
    "            temp_file.write(file_content)\n",
    "\n",
    "        # üîπ Debugging: Check if the file was actually written\n",
    "        file_size = os.path.getsize('temp_nifti.nii')\n",
    "        if file_size == 0:\n",
    "            print(f\"‚ùå Error: 'temp_nifti.nii' was written but is empty! ({gzip_file_path})\")\n",
    "            return None, None\n",
    "        else:\n",
    "            print(f\"‚úÖ Success: 'temp_nifti.nii' was written successfully ({file_size} bytes).\")\n",
    "\n",
    "        img_data, voxel_size = load_nifti_file('temp_nifti.nii')\n",
    "        os.remove('temp_nifti.nii')  # Remove temp file after reading\n",
    "        \n",
    "        return img_data, voxel_size\n",
    "    else:\n",
    "        print(f\"‚ùå Error: Failed to read file content from '{gzip_file_path}'\")\n",
    "        return None, None\n",
    "    \n",
    "def load_patient_structures(patient_folder, patterns):\n",
    "    \"\"\"\n",
    "    Searches the patient folder (recursively) for files matching each regex in patterns,\n",
    "    loads the corresponding NIfTI file, transposes the array using np.transpose(array, (1,0,2)),\n",
    "    and returns a dictionary mapping each pattern key to a tuple (image_array, voxel_size).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_folder : str\n",
    "        The folder path for the patient.\n",
    "    patterns : dict\n",
    "        A dictionary where keys are structure names (e.g. \"image\", \"gtvp\", etc.)\n",
    "        and values are regex patterns (as raw strings) used to match file names.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary where each key (from patterns) is mapped to a tuple (img_array, voxel_size).\n",
    "        Only the first matching file is loaded for each key.\n",
    "    \"\"\"\n",
    "    struct_dict = {}\n",
    "    \n",
    "    # Walk recursively in the patient folder.\n",
    "    for root, dirs, files in os.walk(patient_folder):\n",
    "        for f in files:\n",
    "            # Only consider NIfTI files.\n",
    "            if not (f.endswith(\".nii.gz\") or f.endswith(\".nii\")):\n",
    "                continue\n",
    "            \n",
    "            # Build a search string from the filename.\n",
    "            # If the file starts with \"mask_\", remove that prefix.\n",
    "            if f.startswith(\"mask_\"):\n",
    "                if f.endswith(\".nii.gz\"):\n",
    "                    f_search = f[len(\"mask_\"):-len(\".nii.gz\")]\n",
    "                else:  # endswith(\".nii\")\n",
    "                    f_search = f[len(\"mask_\"):-len(\".nii\")]\n",
    "            else:\n",
    "                if f.endswith(\".nii.gz\"):\n",
    "                    f_search = f[:-len(\".nii.gz\")]\n",
    "                else:  # endswith(\".nii\")\n",
    "                    f_search = f[:-len(\".nii\")]\n",
    "            \n",
    "            # Loop over each pattern.\n",
    "            for key, pat in patterns.items():\n",
    "                # Skip this pattern if we have already loaded a file for it.\n",
    "                if key in struct_dict:\n",
    "                    continue\n",
    "                # Use re.search (case-insensitive) on the f_search string.\n",
    "                if re.search(pat, f_search, flags=re.IGNORECASE):\n",
    "                    file_path = os.path.join(root, f)\n",
    "                    # Load the file using the appropriate function.\n",
    "                    if f.endswith(\".nii.gz\"):\n",
    "                        img, voxel_size = get_image_and_voxel_size_from_gzip(file_path)\n",
    "                    else:\n",
    "                        img, voxel_size = load_nifti_file(file_path)\n",
    "                    if img is not None:\n",
    "                        # Transpose the image as required.\n",
    "                        img = np.transpose(img, (1, 0, 2))\n",
    "                        struct_dict[key] = (img, voxel_size)\n",
    "                        print(f\"Loaded '{key}' from {file_path}\")\n",
    "                    # Stop checking other patterns for this file once a match is found.\n",
    "                    break\n",
    "    return struct_dict\n",
    "\n",
    "def load_patient_data_from_csv(csv_file, root_folder, pat_id = None):\n",
    "    \"\"\"\n",
    "    Loads patient image data and structure masks from a CSV file and a root folder.\n",
    "    \n",
    "    The CSV file is expected to have headers:\n",
    "      Patient ID, Extention, Position, GTVp, Body, Mandible, Spinal Cord\n",
    "    with one row per patient.\n",
    "    \n",
    "    For each patient:\n",
    "      - The patient folder is assumed to be in root_folder and named using the Patient ID\n",
    "        (padded to 8 digits, with any decimals removed).\n",
    "      - The main image is loaded from \"image.nii.gz\" (searched recursively in the patient folder).\n",
    "      - For each structure column (GTVp, Body, Mandible, Spinal Cord):\n",
    "            If the cell is non-empty, the function searches recursively in the patient folder\n",
    "            for a file whose name exactly matches the cell value.\n",
    "      - Each loaded NIfTI file is read (using get_image_and_voxel_size_from_gzip if gzipped,\n",
    "        or load_nifti_file if not), and its array is transposed using np.transpose(array, (1,0,2)).\n",
    "    \n",
    "    The results are stored in a dictionary for each patient with keys:\n",
    "      \"Image\", \"GTVp\", \"Body\", \"Mandibula\", \"Spinal Cord\"\n",
    "    (Note: you can adjust the keys if needed.)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file : str\n",
    "        Path to the CSV file.\n",
    "    root_folder : str\n",
    "        Root folder that contains patient folders (each named after a patient ID).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary mapping each patient ID (string) to another dictionary with keys as above,\n",
    "        and values equal to tuples (image_array, voxel_size).\n",
    "    \"\"\"\n",
    "    #patient_data = {}\n",
    "    \n",
    "    # Read CSV file.\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Define the structure columns (excluding Patient ID, Extention, and Position)\n",
    "    structure_columns = [\"GTVp\", \"Body\", \"Mandible\", \"Spinal Cord\"]\n",
    "\n",
    "    if pat_id is not None:\n",
    "        df = df[df[\"Patient ID\"] == pat_id]\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        # Get patient id, remove decimals and pad to 8 digits.\n",
    "        print(f\"Processing row {idx} out of {len(df)} ...\")\n",
    "        try:\n",
    "            pid_num = float(row[\"Patient ID\"])\n",
    "            patient_id = str(int(pid_num)).zfill(8)\n",
    "        except Exception as e:\n",
    "            print(f\"Invalid Patient ID at row {idx}: {row['Patient ID']}. Skipping.\")\n",
    "            continue\n",
    "        if np.isnan(pid_num):\n",
    "            print(f\"Invalid Patient ID at row {idx}: {row['Patient ID']}. Skipping.\")\n",
    "            continue\n",
    "        print(f\"Processing patient {patient_id} ...\")\n",
    "        if pd.isna(row[\"GTVp\"]):\n",
    "            print(f\"Patient {patient_id} has no GTVp. Skipping.\")\n",
    "            continue\n",
    "        # Patient folder is assumed to be root_folder/patient_id\n",
    "        patient_folder = os.path.join(root_folder, patient_id)\n",
    "        if not os.path.isdir(patient_folder):\n",
    "            print(f\"Patient folder {patient_folder} not found. Skipping patient {patient_id}.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        pdata = {}\n",
    "        \n",
    "        # 1. Load the main image (\"image.nii.gz\")\n",
    "        main_image_path = None\n",
    "        # Search for \"image.nii.gz\" in patient_folder recursively.\n",
    "        for root, dirs, files in os.walk(patient_folder):\n",
    "            if \"image.nii.gz\" in files:\n",
    "                main_image_path = os.path.join(root, \"image.nii.gz\")\n",
    "                break\n",
    "        if main_image_path is None:\n",
    "            print(f\"Main image 'image.nii.gz' not found for patient {patient_id}. Skipping.\")\n",
    "            continue\n",
    "        # Load main image.\n",
    "        img_data, voxel_size = get_image_and_voxel_size_from_gzip(main_image_path)\n",
    "        if img_data is None:\n",
    "            print(f\"Failed to load main image for patient {patient_id}.\")\n",
    "            continue\n",
    "        img_data = np.transpose(img_data, (1, 0, 2))\n",
    "        print(f\"Hu value range: {np.min(img_data)}, {np.max(img_data)}\")\n",
    "        pdata[\"Image\"] = (img_data, voxel_size)\n",
    "        \n",
    "        # 2. For each structure, read the corresponding file.\n",
    "        for col in structure_columns:\n",
    "            file_name = str(row[col]).strip()\n",
    "            if not file_name or file_name.lower() in ['nan', '']:\n",
    "                # Skip if cell is empty.\n",
    "                continue\n",
    "            \n",
    "            structure_file_path = None\n",
    "            # Search recursively for an exact filename match.\n",
    "            for root, dirs, files in os.walk(patient_folder):\n",
    "                # Compare case-insensitively.\n",
    "                for f in files:\n",
    "                    if f.lower() == file_name.lower():\n",
    "                        structure_file_path = os.path.join(root, f)\n",
    "                        break\n",
    "                if structure_file_path is not None:\n",
    "                    break\n",
    "            \n",
    "            if structure_file_path is None:\n",
    "                print(f\"File for structure '{col}' with name '{file_name}' not found for patient {patient_id}.\")\n",
    "                continue\n",
    "            \n",
    "            # Load the structure file.\n",
    "            if structure_file_path.endswith(\".nii.gz\"):\n",
    "                struct_img, struct_voxel_size = get_image_and_voxel_size_from_gzip(structure_file_path)\n",
    "                \n",
    "            else:\n",
    "                struct_img, struct_voxel_size = load_nifti_file(structure_file_path)\n",
    "            if struct_img is None:\n",
    "                print(f\"Failed to load structure '{col}' for patient {patient_id} from file {structure_file_path}.\")\n",
    "                continue\n",
    "            struct_img = np.transpose(struct_img, (1, 0, 2))\n",
    "            if struct_img.size == 0:\n",
    "                print(f\"Structure '{col}' for patient {patient_id} is empty. Skipping.\")\n",
    "                continue\n",
    "            pdata[col] = (struct_img, struct_voxel_size)\n",
    "            print(f\"Loaded {col} from {structure_file_path}\")\n",
    "            \n",
    "            # if \"GTVp\" in pdata:\n",
    "            #     gtvp_array = pdata[\"GTVp\"][0]\n",
    "            #     nonzero_count = np.count_nonzero(gtvp_array)\n",
    "            #     print(f\"Number of nonzero elements in 'gtvp': {nonzero_count}\")\n",
    "        # Store the patient data.\n",
    "        #patient_data[patient_id] = pdata\n",
    "        \n",
    "        # Optionally, you could display an interactive widget here for this patient:\n",
    "        display_patient_overlay_structures(pdata, title=f\"Patient {patient_id} Overlay\")\n",
    "        \n",
    "    \n",
    "    #return patient_data\n",
    "\n",
    "def load_patient_data_from_row(row, root_folder):\n",
    "    \"\"\"\n",
    "    Given one row from the CSV and the root folder containing patient folders,\n",
    "    load the patient's main image and structure files as specified by the row.\n",
    "    \n",
    "    The CSV is expected to have headers:\n",
    "      Patient ID, Extention, Position, GTVp, Body, Mandible, Spinal Cord.\n",
    "      \n",
    "    For the patient:\n",
    "      - The patient folder is assumed to be located at root_folder/patient_id,\n",
    "        where patient_id is the Patient ID padded to 8 digits (with any decimals removed).\n",
    "      - The main image is loaded from \"image.nii.gz\" (searched recursively).\n",
    "      - For each structure column (GTVp, Body, Mandible, Spinal Cord), if the CSV cell is non-empty,\n",
    "        the function searches recursively for a file whose name exactly matches the cell value.\n",
    "      - Each loaded NIfTI file is transposed using np.transpose(array, (1, 0, 2)).\n",
    "      \n",
    "    Parameters\n",
    "    ----------\n",
    "    row : pandas.Series\n",
    "        One row from the CSV file.\n",
    "    root_folder : str\n",
    "        The root folder that contains patient folders (named by padded patient IDs).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple or (None, patient_id)\n",
    "        If successful, returns a tuple (patient_data, patient_id) where patient_data is a dictionary\n",
    "        with keys such as \"Image\", \"GTVp\", \"Body\", \"Mandible\", and \"Spinal Cord\" mapping to a tuple\n",
    "        (image_array, voxel_size). If the main image cannot be loaded or the patient folder is missing,\n",
    "        returns (None, patient_id).\n",
    "    \"\"\"\n",
    "    # Convert Patient ID to a float, then to an int to remove decimals, and pad to 8 digits.\n",
    "    try:\n",
    "        pid_num = float(row[\"Patient ID\"])\n",
    "        patient_id = str(int(pid_num)).zfill(8)\n",
    "    except Exception as e:\n",
    "        print(f\"Invalid Patient ID '{row['Patient ID']}' in row, skipping.\")\n",
    "        return None, None\n",
    "\n",
    "    # Build the patient folder path.\n",
    "    patient_folder = os.path.join(root_folder, patient_id)\n",
    "    if not os.path.isdir(patient_folder):\n",
    "        print(f\"Patient folder {patient_folder} not found for patient {patient_id}.\")\n",
    "        return None, patient_id\n",
    "\n",
    "    pdata = {}\n",
    "\n",
    "    # 1. Load the main image (\"image.nii.gz\")\n",
    "    main_image_path = None\n",
    "    for root_dir, dirs, files in os.walk(patient_folder):\n",
    "        if \"image.nii.gz\" in files:\n",
    "            main_image_path = os.path.join(root_dir, \"image.nii.gz\")\n",
    "            break\n",
    "    if main_image_path is None:\n",
    "        print(f\"Main image 'image.nii.gz' not found for patient {patient_id}.\")\n",
    "        return None, patient_id\n",
    "\n",
    "    img_data, voxel_size = get_image_and_voxel_size_from_gzip(main_image_path)\n",
    "    if img_data is None:\n",
    "        print(f\"Failed to load main image for patient {patient_id}.\")\n",
    "        return None, patient_id\n",
    "    # Transpose the array as required.\n",
    "    img_data = np.transpose(img_data, (1, 0, 2))\n",
    "    pdata[\"Image\"] = (img_data, voxel_size)\n",
    "\n",
    "    # 2. Process structure columns.\n",
    "    structure_columns = [\"GTVp\", \"Body\", \"Mandible\", \"Spinal Cord\"]\n",
    "    for col in structure_columns:\n",
    "        file_name = str(row[col]).strip()\n",
    "        if not file_name or file_name.lower() in ['nan', '']:\n",
    "            continue  # Skip empty entries.\n",
    "        \n",
    "        structure_file_path = None\n",
    "        # Search recursively in the patient folder for an exact filename match (case-insensitive).\n",
    "        for root_dir, dirs, files in os.walk(patient_folder):\n",
    "            for f in files:\n",
    "                if f.lower() == file_name.lower():\n",
    "                    structure_file_path = os.path.join(root_dir, f)\n",
    "                    break\n",
    "            if structure_file_path is not None:\n",
    "                break\n",
    "        \n",
    "        if structure_file_path is None:\n",
    "            print(f\"File for structure '{col}' with name '{file_name}' not found for patient {patient_id}.\")\n",
    "            continue\n",
    "        \n",
    "        # Load the structure file.\n",
    "        if structure_file_path.endswith(\".nii.gz\"):\n",
    "            struct_img, struct_voxel_size = get_image_and_voxel_size_from_gzip(structure_file_path)\n",
    "            \n",
    "        else:\n",
    "            struct_img, struct_voxel_size = load_nifti_file(structure_file_path)\n",
    "        if struct_img is None:\n",
    "            print(f\"Failed to load structure '{col}' for patient {patient_id} from {structure_file_path}.\")\n",
    "            continue\n",
    "        \n",
    "        # Transpose the array.\n",
    "        struct_img = np.transpose(struct_img, (1, 0, 2))\n",
    "        pdata[col] = (struct_img, struct_voxel_size)\n",
    "        print(f\"Loaded {col} from {structure_file_path}\")\n",
    "    \n",
    "    return pdata, patient_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_via_threshold(ct_image, HU_range=(900, 2500)):\n",
    "    \"\"\"\n",
    "    Generate a bone mask from a CT image by thresholding within a specified HU range.\n",
    "\n",
    "    Parameters:\n",
    "    ct_image (numpy.ndarray): The 3D CT image data.\n",
    "    HU_range (tuple): The range of Hounsfield Units to identify bone. Default is (700, 2000).\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The 3D bone mask with bone as 1 and all other as 0.\n",
    "    \"\"\"\n",
    "    bone_mask = np.zeros_like(ct_image)\n",
    "    lower_bound, upper_bound = HU_range\n",
    "    #print(f\"Applying HU range: {lower_bound} to {upper_bound}\")\n",
    "    #print(f\"CT image min value: {np.min(ct_image)}, max value: {np.max(ct_image)}\")\n",
    "    bone_mask[(ct_image >= lower_bound) & (ct_image <= upper_bound)] = 1\n",
    "    #print(f\"Bone mask generated with shape: {bone_mask.shape}, number of bone voxels: {np.sum(bone_mask)}\")\n",
    "    return bone_mask\n",
    "\n",
    "def get_nonzero_slice_range(image_data, slice_dir_indx=2):\n",
    "    \"\"\"\n",
    "    Get the range of slices that contain non-zero values in a 3D image.\n",
    "    \n",
    "    This function computes which slices along the specified dimension contain \n",
    "    any non-zero elements by collapsing the other two dimensions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_data : numpy.ndarray\n",
    "        The 3D image data.\n",
    "    slice_dir_indx : int, optional\n",
    "        The index of the slice direction (0, 1, or 2). Default is 2.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple (start, end) where start is the first slice index and end is the last \n",
    "        slice index that contain non-zero values.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If no non-zero slices are found or if slice_dir_indx is not 0, 1, or 2.\n",
    "    \"\"\"\n",
    "    if image_data.ndim != 3:\n",
    "        raise ValueError(\"image_data must be a 3D array.\")\n",
    "    if slice_dir_indx not in (0, 1, 2):\n",
    "        raise ValueError(\"slice_dir_indx must be 0, 1, or 2.\")\n",
    "    \n",
    "    # Determine which axes to collapse for the nonzero test.\n",
    "    if slice_dir_indx == 0:\n",
    "        collapsed = np.any(image_data, axis=(1, 2))\n",
    "    elif slice_dir_indx == 1:\n",
    "        collapsed = np.any(image_data, axis=(0, 2))\n",
    "    else:  # slice_dir_indx == 2\n",
    "        collapsed = np.any(image_data, axis=(0, 1))\n",
    "    \n",
    "    nonzero_indices = np.nonzero(collapsed)[0]\n",
    "    if nonzero_indices.size == 0:\n",
    "        raise ValueError(\"No non-zero slices found in the specified direction.\")\n",
    "    \n",
    "    start = int(nonzero_indices[0])\n",
    "    end = int(nonzero_indices[-1])\n",
    "    \n",
    "    return start, end\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "def estimate_and_plot_bone_range(image, mandible_mask=None, spinal_cord_mask=None, plot_hist=True):\n",
    "    \"\"\"\n",
    "    Estimate the range of bone Hounsfield Unit (HU) values from a CT image using Otsu's thresholding\n",
    "    applied to optional structure masks for the mandible and spinal cord.\n",
    "    \n",
    "    The function operates as follows:\n",
    "      - If both mandible_mask and spinal_cord_mask are provided:\n",
    "          * Compute Otsu's threshold for the mandible mask and for the spinal cord mask.\n",
    "          * For the spinal cord, use the minimum intensity among voxels above threshold as the lower bound.\n",
    "          * For the mandible, use the mean intensity of voxels above threshold as the upper bound.\n",
    "      - If only one mask is provided, compute Otsu's threshold on that mask and use the minimum and maximum \n",
    "        intensities (above threshold) as the bone range.\n",
    "      - If neither mask is provided, return None.\n",
    "    \n",
    "    Additionally, if plot_hist is True, the function plots the intensity histograms for each available mask,\n",
    "    with a vertical dashed line indicating the Otsu threshold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        3D CT image array.\n",
    "    mandible_mask : numpy.ndarray, optional\n",
    "        3D binary mask for the mandible.\n",
    "    spinal_cord_mask : numpy.ndarray, optional\n",
    "        3D binary mask for the spinal cord.\n",
    "    plot_hist : bool, optional\n",
    "        If True, display intensity histograms with the computed Otsu threshold. Default is True.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple or None\n",
    "        If at least one mask is provided and valid voxels are found, returns a tuple (min_HU, max_HU)\n",
    "        representing the estimated bone HU range; otherwise, returns None.\n",
    "    \"\"\"\n",
    "    def get_voxels(mask):\n",
    "        return image[mask.astype(bool)]\n",
    "    \n",
    "    # Process when both masks are available.\n",
    "    if mandible_mask is not None and spinal_cord_mask is not None:\n",
    "        mandible_voxels = get_voxels(mandible_mask)\n",
    "        spinal_voxels = get_voxels(spinal_cord_mask)\n",
    "        if mandible_voxels.size == 0 or spinal_voxels.size == 0:\n",
    "            return None\n",
    "        thresh_mandib = threshold_otsu(mandible_voxels)\n",
    "        thresh_spinal = threshold_otsu(spinal_voxels)\n",
    "        \n",
    "        mandible_above = mandible_voxels[mandible_voxels > thresh_mandib]\n",
    "        spinal_above = spinal_voxels[spinal_voxels > thresh_spinal]\n",
    "        if mandible_above.size == 0 or spinal_above.size == 0:\n",
    "            return None\n",
    "        \n",
    "        min_HU = np.min(spinal_above)   # Lower bound from spinal cord\n",
    "        max_HU = np.mean(mandible_above)  # Upper bound from mandible\n",
    "        \n",
    "        if plot_hist:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "            ax1.hist(mandible_voxels, bins=50, color='blue', alpha=0.7)\n",
    "            ax1.axvline(thresh_mandib, color='black', linestyle='--', \n",
    "                        label=f'Otsu thresh = {thresh_mandib:.1f}')\n",
    "            ax1.set_title('Mandible Intensity Histogram')\n",
    "            ax1.legend()\n",
    "            \n",
    "            ax2.hist(spinal_voxels, bins=50, color='green', alpha=0.7)\n",
    "            ax2.axvline(thresh_spinal, color='black', linestyle='--', \n",
    "                        label=f'Otsu thresh = {thresh_spinal:.1f}')\n",
    "            ax2.set_title('Spinal Cord Intensity Histogram')\n",
    "            ax2.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        return (min_HU, max_HU)\n",
    "    \n",
    "    # Process if only the mandible mask is provided.\n",
    "    if mandible_mask is not None and spinal_cord_mask is None:\n",
    "        mandible_voxels = get_voxels(mandible_mask)\n",
    "        if mandible_voxels.size == 0:\n",
    "            return None\n",
    "        thresh = threshold_otsu(mandible_voxels)\n",
    "        voxels_above = mandible_voxels[mandible_voxels > thresh]\n",
    "        if voxels_above.size == 0:\n",
    "            return None\n",
    "        if plot_hist:\n",
    "            plt.figure(figsize=(6,5))\n",
    "            plt.hist(mandible_voxels, bins=50, color='blue', alpha=0.7)\n",
    "            plt.axvline(thresh, color='black', linestyle='--', label=f'Otsu thresh = {thresh:.1f}')\n",
    "            plt.title('Mandible Intensity Histogram')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        return (np.min(voxels_above), np.max(voxels_above))\n",
    "    \n",
    "    # Process if only the spinal cord mask is provided.\n",
    "    if spinal_cord_mask is not None and mandible_mask is None:\n",
    "        spinal_voxels = get_voxels(spinal_cord_mask)\n",
    "        if spinal_voxels.size == 0:\n",
    "            return None\n",
    "        thresh = threshold_otsu(spinal_voxels)\n",
    "        voxels_above = spinal_voxels[spinal_voxels > thresh]\n",
    "        if voxels_above.size == 0:\n",
    "            return None\n",
    "        if plot_hist:\n",
    "            plt.figure(figsize=(6,5))\n",
    "            plt.hist(spinal_voxels, bins=50, color='green', alpha=0.7)\n",
    "            plt.axvline(thresh, color='black', linestyle='--', label=f'Otsu thresh = {thresh:.1f}')\n",
    "            plt.title('Spinal Cord Intensity Histogram')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        return (np.min(voxels_above), np.max(voxels_above))\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_angles(vector):\n",
    "    \"\"\"\n",
    "    Calculate the distance from the origin and the angles in the xy and xz planes with respect to the x-axis.\n",
    "\n",
    "    Parameters:\n",
    "    vector (tuple): A tuple representing the vector (x, y, z).\n",
    "\n",
    "    Returns:\n",
    "    tuple: The distance from the origin, the angle in the xy plane, and the angle in the xz plane.\n",
    "    \"\"\"\n",
    "    x, y, z = vector\n",
    "\n",
    "    # Calculate the distance from the origin\n",
    "    distance = np.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "    # Calculate the angle in the xy plane with respect to the x-axis\n",
    "    angle_xy = np.arctan2(y, x)\n",
    "    angle_xy_deg = np.degrees(angle_xy)\n",
    "\n",
    "    # Calculate the angle in the xz plane with respect to the x-axis\n",
    "    angle_xz = np.arctan2(z, x)\n",
    "    angle_xz_deg = np.degrees(angle_xz)\n",
    "\n",
    "    return angle_xy, angle_xz, distance\n",
    "\n",
    "def angles_to_vector(angle_xy, angle_xz, distance):\n",
    "    \"\"\"\n",
    "    Calculate the vector components given the distance from the origin and the angles in the xy and xz planes.\n",
    "\n",
    "    Parameters:\n",
    "    distance (float): The distance from the origin.\n",
    "    angle_xy (float): The angle in the xy plane with respect to the x-axis.\n",
    "    angle_xz (float): The angle in the xz plane with respect to the x-axis.\n",
    "\n",
    "    Returns:\n",
    "    tuple: The vector components (x, y, z).\n",
    "    \"\"\"\n",
    "    x = distance * np.cos(angle_xy) * np.cos(angle_xz)\n",
    "    y = distance * np.sin(angle_xy) * np.cos(angle_xz)\n",
    "    z = distance * np.sin(angle_xz)\n",
    "    \n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_intensity_to_mirror_voxels(I_orig, x, x_m):\n",
    "    \"\"\"\n",
    "    Assigns intensities from I_orig to a mirror image based on mirror voxel positions.\n",
    "    \n",
    "    For each voxel index in x (of shape (N, 3)), the corresponding mirror position\n",
    "    in x_m (which is computed in continuous (float) coordinates) is rounded to the nearest\n",
    "    integer indices. Then, the intensity at the original voxel (from I_orig) is assigned to\n",
    "    the mirror voxel location in a new image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    I_orig : numpy.ndarray\n",
    "        The original 3D image (e.g., a CT scan) with shape (X, Y, Z).\n",
    "    x : numpy.ndarray\n",
    "        Array of voxel coordinates (shape (N, 3)) corresponding to the original image points.\n",
    "    x_m : numpy.ndarray\n",
    "        Array of mirror voxel positions (shape (N, 3)) computed in continuous (float) coordinates.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    I_m : numpy.ndarray\n",
    "        A new 3D image of the same shape as I_orig, where each rounded mirror voxel position \n",
    "        is assigned the intensity from I_orig corresponding to the original voxel.\n",
    "    \"\"\"\n",
    "    # Initialize the mirror image (I_m) with zeros (or choose a background value if needed).\n",
    "    I_m = np.zeros_like(I_orig)\n",
    "    \n",
    "    # Round the mirror voxel positions to the nearest integers.\n",
    "    x_m_rounded = np.rint(x_m).astype(int)\n",
    "    \n",
    "    # Clip the indices to ensure they are within the valid range of the image dimensions.\n",
    "    x_m_rounded[:, 0] = np.clip(x_m_rounded[:, 0], 0, I_orig.shape[0] - 1)\n",
    "    x_m_rounded[:, 1] = np.clip(x_m_rounded[:, 1], 0, I_orig.shape[1] - 1)\n",
    "    x_m_rounded[:, 2] = np.clip(x_m_rounded[:, 2], 0, I_orig.shape[2] - 1)\n",
    "    \n",
    "    # Assign the intensity from I_orig (using voxel indices in x) to I_m at the corresponding rounded mirror indices.\n",
    "    I_m[x_m_rounded[:, 0], x_m_rounded[:, 1], x_m_rounded[:, 2]] = I_orig[x[:, 0], x[:, 1], x[:, 2]]\n",
    "    \n",
    "    return I_m\n",
    "\n",
    "# def compute_objective(params_array, image, interpolator_intensity, interpolators_gradient):\n",
    "#     \"\"\"\n",
    "#     Compute the objective function:\n",
    "#         f(theta, phi, L) = (1/N) * sum_i [ I(x_i) - I(x_m,i) ]^2,\n",
    "#     where the mirror voxel is defined as:\n",
    "#         x_m = x - 2 * alpha * n,\n",
    "#     with\n",
    "#         n = [cos(phi)*cos(theta), cos(phi)*sin(theta), sin(phi)]\n",
    "#         alpha = cos(phi)*cos(theta)*x + cos(phi)*sin(theta)*y + sin(phi)*z - L.\n",
    "    \n",
    "#     The voxel indices x are taken from the nonzero elements of the image.\n",
    "    \n",
    "#     Parameters:\n",
    "#       theta : float\n",
    "#           Rotation angle around the z-axis.\n",
    "#       phi : float\n",
    "#           Rotation angle around the y-axis.\n",
    "#       L : float\n",
    "#           Offset along the normal.\n",
    "#       image : 3D numpy array\n",
    "#           The intensity image.\n",
    "#       interpolator_intensity : RegularGridInterpolator\n",
    "#           Interpolator to get the intensity I at any (x,y,z) location.\n",
    "#       interpolators_gradient : dict\n",
    "#           Dictionary with keys 'x', 'y', 'z' containing RegularGridInterpolator\n",
    "#           objects for the gradient components (not used in this function).\n",
    "    \n",
    "#     Returns:\n",
    "#       f : float\n",
    "#           The value of the objective function.\n",
    "#     \"\"\"\n",
    "#     # Extract parameters\n",
    "#     theta, phi, L = params_array[0], params_array[1], params_array[2]\n",
    "#     # Extract voxel indices (nonzero elements) as an array of shape (N,3)\n",
    "#     indices_image = np.array(np.nonzero(image)).T  # each row is [x, y, z]\n",
    "#     indices_coord_syst = np.array([indices_image[:, 1], indices_image[:, 0], indices_image[:, 2]]).T\n",
    "#     N = indices_image.shape[0]\n",
    "    \n",
    "#     # Define the unit normal vector n based on theta and phi.\n",
    "#     n = np.array([np.cos(phi)*np.cos(theta),\n",
    "#                   np.cos(phi)*np.sin(theta),\n",
    "#                   np.sin(phi)])\n",
    "    \n",
    "#     # Compute d for each voxel.\n",
    "#     d = (np.cos(phi)*np.cos(theta)*indices_coord_syst[:, 0] +\n",
    "#              np.cos(phi)*np.sin(theta)*indices_coord_syst[:, 1] +\n",
    "#              np.sin(phi)*indices_coord_syst[:, 2] - L)  # shape (N,)\n",
    "    \n",
    "#     # Compute mirror voxel coordinates vectorized.\n",
    "#     x_m_coord_syst = indices_coord_syst - 2 * d[:, None] * n[None, :]\n",
    "#     x_m_image = np.array([x_m_coord_syst[:, 1], x_m_coord_syst[:, 0], x_m_coord_syst[:, 2]]).T\n",
    "#     # Evaluate intensity at mirror voxel positions.\n",
    "#     I_m = interpolator_intensity(x_m_image)\n",
    "    \n",
    "    \n",
    "#     # Get original intensity values from the image.\n",
    "#     I_orig = image[indices_image[:, 0], indices_image[:, 1], indices_image[:, 2]]\n",
    "    \n",
    "#     # Compute the mean square error.\n",
    "#     diff = I_orig - I_m\n",
    "#     f = (1.0 / N) * np.sum(diff ** 2)\n",
    "\n",
    "#     # # Visualize the mirror image on middle slice\n",
    "#     # I_mirror = assign_intensity_to_mirror_voxels(image, indices_image, x_m_image)\n",
    "\n",
    "#     # plt.imshow(I_mirror[:, :, image.shape[2] // 2] + image[:, :, image.shape[2] // 2], cmap='gray')\n",
    "#     # plt.show()\n",
    "\n",
    "\n",
    "#     return f\n",
    "\n",
    "def compute_signed_distances(params_array, image):\n",
    "    \"\"\"\n",
    "    Compute the signed distances of nonzero voxels in a 3D image from a plane,\n",
    "    using the parameterization [theta, phi, L].\n",
    "    \n",
    "    The image is assumed to have coordinate zero at the top left corner.\n",
    "    The plane is defined via:\n",
    "      n = [cos(phi)*cos(theta), cos(phi)*sin(theta), sin(phi)]\n",
    "      P0 = L * n\n",
    "    and the signed distance for a voxel x (in the modified coordinate system) is:\n",
    "      d = cos(phi)*cos(theta)*x' + cos(phi)*sin(theta)*y' + sin(phi)*z - L,\n",
    "    where the voxel coordinates are obtained by first extracting the nonzero indices\n",
    "    (each row as [x, y, z]) and then swapping the first two coordinates to obtain\n",
    "    the coordinate system used in the computation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params_array : array-like, shape (3,)\n",
    "        The parameters [theta, phi, L], with theta and phi in radians and L in voxel units.\n",
    "    image : numpy.ndarray\n",
    "        The 3D image (e.g., a CT image), where coordinate zero is in the top left corner.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    d : numpy.ndarray\n",
    "        A 1D array of signed distances for each nonzero voxel.\n",
    "    indices_coord_syst : numpy.ndarray\n",
    "        The modified voxel coordinate array corresponding to the computed distances.\n",
    "    \"\"\"\n",
    "    # Extract parameters.\n",
    "    theta, phi, L = params_array[0], params_array[1], params_array[2]\n",
    "    \n",
    "    # Extract voxel indices (nonzero elements) as an array of shape (N,3).\n",
    "    indices_image = np.array(np.nonzero(image)).T  # each row is [x, y, z]\n",
    "    \n",
    "    # Convert indices to the coordinate system used in the computation (swap first two dimensions).\n",
    "    indices_coord_syst = np.array([indices_image[:, 1], indices_image[:, 0], indices_image[:, 2]]).T\n",
    "    N = indices_image.shape[0]\n",
    "    \n",
    "    # Define the unit normal vector n based on theta and phi.\n",
    "    n = np.array([np.cos(phi)*np.cos(theta),\n",
    "                  np.cos(phi)*np.sin(theta),\n",
    "                  np.sin(phi)])\n",
    "    \n",
    "    # Compute signed distance d for each voxel.\n",
    "    d = (np.cos(phi)*np.cos(theta)*indices_coord_syst[:, 0] +\n",
    "         np.cos(phi)*np.sin(theta)*indices_coord_syst[:, 1] +\n",
    "         np.sin(phi)*indices_coord_syst[:, 2] - L)\n",
    "    \n",
    "    return d, n, indices_coord_syst, indices_image\n",
    "\n",
    "\n",
    "def huber_loss(diff, delta=100):\n",
    "    \"\"\"\n",
    "    Compute the Huber loss for the given differences.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    diff : numpy.ndarray\n",
    "        The difference between original and mirrored intensities.\n",
    "    delta : float, optional\n",
    "        The threshold at which to switch between quadratic and linear loss (default 100).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The Huber loss computed elementwise.\n",
    "    \"\"\"\n",
    "    # For errors smaller than delta, use quadratic loss.\n",
    "    # For errors larger than delta, use linear loss.\n",
    "    loss = np.where(np.abs(diff) <= delta, 0.5 * diff**2,\n",
    "                    delta * (np.abs(diff) - 0.5 * delta))\n",
    "    return loss\n",
    "\n",
    "def compute_objective(params_array, image, interpolator_intensity, interpolators_gradient):\n",
    "    \"\"\"\n",
    "    Compute the objective function using Huber loss:\n",
    "    \n",
    "        f(theta, phi, L) = (1/N) * sum_i huber_loss( I(x_i) - I(x_m,i) )\n",
    "        \n",
    "    where the mirror voxel is defined as:\n",
    "        x_m = x - 2 * alpha * n,\n",
    "    with\n",
    "        n = [cos(phi)*cos(theta), cos(phi)*sin(theta), sin(phi)]\n",
    "        alpha = cos(phi)*cos(theta)*x + cos(phi)*sin(theta)*y + sin(phi)*z - L.\n",
    "    \n",
    "    The voxel indices x are taken from the nonzero elements of the image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params_array : array-like, shape (3,)\n",
    "        Array containing the parameters [theta, phi, L].\n",
    "    image : numpy.ndarray\n",
    "        The 3D intensity image.\n",
    "    interpolator_intensity : RegularGridInterpolator\n",
    "        Interpolator to get the intensity I at any (x, y, z) position.\n",
    "    interpolators_gradient : dict\n",
    "        Dictionary with keys 'x', 'y', and 'z' containing RegularGridInterpolator\n",
    "        objects for the gradient components (not used in this function).\n",
    "    delta : float, optional\n",
    "        Delta parameter for the Huber loss (default is 100).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    f : float\n",
    "        The value of the objective function.\n",
    "    \"\"\"\n",
    "    d, n, indices_coord_syst, indices_image = compute_signed_distances(params_array, image)\n",
    "    N = len(d)\n",
    "    \n",
    "    # Compute mirror voxel coordinates vectorized.\n",
    "    x_m_coord_syst = indices_coord_syst - 2 * d[:, None] * n[None, :]\n",
    "    # Convert back to image coordinate system by swapping axes.\n",
    "    x_m_image = np.array([x_m_coord_syst[:, 1], x_m_coord_syst[:, 0], x_m_coord_syst[:, 2]]).T\n",
    "    \n",
    "    # Evaluate intensity at mirror voxel positions.\n",
    "    I_m = interpolator_intensity(x_m_image)\n",
    "    \n",
    "    # Get original intensity values from the image.\n",
    "    I_orig = image[indices_image[:, 0], indices_image[:, 1], indices_image[:, 2]]\n",
    "    \n",
    "    # Compute the difference.\n",
    "    diff = I_orig - I_m\n",
    "    # Compute the objective using the Huber loss.\n",
    "    #f = (1.0 / N) * np.sum(huber_loss(diff, delta=300))\n",
    "    f = (1.0 / N) * np.sum(diff **2)\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(param_array, image, interpolator_intensity, interpolators_gradient):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the objective function\n",
    "        f(theta, phi, L) = (1/N)*sum_{i}[ I(x_i) - I(x_m,i) ]^2,\n",
    "    with respect to the parameters theta, phi, and L.\n",
    "    \n",
    "    The mirror voxel for each voxel x is defined as:\n",
    "        x_m = x - 2 * alpha * n,\n",
    "    where\n",
    "        n = [cos(phi)*cos(theta), cos(phi)*sin(theta), sin(phi)]\n",
    "        alpha = cos(phi)*cos(theta)*x + cos(phi)*sin(theta)*y + sin(phi)*z - L.\n",
    "    \n",
    "    The function extracts the indices of the nonzero elements in the image as x.\n",
    "    \n",
    "    Parameters:\n",
    "      theta : float\n",
    "          Rotation angle around the z-axis.\n",
    "      phi : float\n",
    "          Rotation angle around the y-axis.\n",
    "      L : float\n",
    "          Offset along the normal.\n",
    "      image : 3D numpy array\n",
    "          The intensity image.\n",
    "      interpolator_intensity : RegularGridInterpolator\n",
    "          Interpolator to get the intensity I at any (x,y,z) location.\n",
    "      interpolators_gradient : dict\n",
    "          Dictionary with keys 'x', 'y', and 'z' containing RegularGridInterpolator\n",
    "          objects for the gradient components of the image.\n",
    "    \n",
    "    Returns:\n",
    "      grad : numpy array of shape (3,)\n",
    "          The gradient [df/dtheta, df/dphi, df/dL].\n",
    "    \"\"\"\n",
    "    # Get voxel indices (x) as an array of shape (N, 3) from nonzero elements.\n",
    "    theta, phi, L = param_array[0], param_array[1], param_array[2]\n",
    "    indices = np.array(np.nonzero(image)).T  # each row is [x, y, z]\n",
    "    N = indices.shape[0]\n",
    "    \n",
    "    # Define the unit normal vector n.\n",
    "    n = np.array([np.cos(phi)*np.cos(theta),\n",
    "                  np.cos(phi)*np.sin(theta),\n",
    "                  np.sin(phi)])\n",
    "    \n",
    "    # Compute alpha for each voxel.\n",
    "    # indices[:,0] -> x, indices[:,1] -> y, indices[:,2] -> z.\n",
    "    alpha = (np.cos(phi)*np.cos(theta)*indices[:,0] +\n",
    "             np.cos(phi)*np.sin(theta)*indices[:,1] +\n",
    "             np.sin(phi)*indices[:,2] - L)  # shape (N,)\n",
    "    \n",
    "    # Compute mirror voxels x_m vectorized.\n",
    "    # x_m = x - 2*alpha*n, broadcasting n (shape (3,)) and alpha (shape (N,))\n",
    "    x_m = indices - 2 * alpha[:, None] * n[None, :]\n",
    "    \n",
    "    # Evaluate the intensity at the mirror voxel positions.\n",
    "    I_m = interpolator_intensity(x_m)\n",
    "    # Get the intensity at the original voxel positions from the image.\n",
    "    I_orig = image[indices[:,0], indices[:,1], indices[:,2]]\n",
    "    \n",
    "    # Compute the difference d = I(x) - I(x_m) for each voxel.\n",
    "    d = I_orig - I_m  # shape (N,)\n",
    "    \n",
    "    # Evaluate the gradient of the intensity at mirror positions.\n",
    "    grad_x = interpolators_gradient['x'](x_m)\n",
    "    grad_y = interpolators_gradient['y'](x_m)\n",
    "    grad_z = interpolators_gradient['z'](x_m)\n",
    "    grad_I = np.stack([grad_x, grad_y, grad_z], axis=1)  # shape (N, 3)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Compute the derivatives of x_m with respect to each parameter.\n",
    "    # -------------------------------\n",
    "    # For L:\n",
    "    d_xm_dL = 2 * n  # shape (3,)\n",
    "    \n",
    "    # For theta:\n",
    "    # term_theta = cos(phi)*sin(theta)*x - cos(phi)*cos(theta)*y\n",
    "    term_theta = np.cos(phi)*np.sin(theta)*indices[:,0] - np.cos(phi)*np.cos(theta)*indices[:,1]\n",
    "    d_xm_dtheta = 2 * ( term_theta[:, None] * n[None, :] +\n",
    "                        alpha[:, None] * np.array([np.cos(phi)*np.sin(theta),\n",
    "                                                   -np.cos(phi)*np.cos(theta),\n",
    "                                                    0]) )\n",
    "    \n",
    "    # For phi:\n",
    "    # term_phi = sin(phi)*cos(theta)*x + sin(phi)*sin(theta)*y - cos(phi)*z\n",
    "    term_phi = (np.sin(phi)*np.cos(theta)*indices[:,0] +\n",
    "                np.sin(phi)*np.sin(theta)*indices[:,1] -\n",
    "                np.cos(phi)*indices[:,2])\n",
    "    d_xm_dphi = 2 * ( term_phi[:, None] * n[None, :] +\n",
    "                      alpha[:, None] * np.array([np.sin(phi)*np.cos(theta),\n",
    "                                                 np.sin(phi)*np.sin(theta),\n",
    "                                                -np.cos(phi)]) )\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Compute dot products between grad_I and the derivatives of x_m.\n",
    "    dot_theta = np.sum(grad_I * d_xm_dtheta, axis=1)  # shape (N,)\n",
    "    dot_phi   = np.sum(grad_I * d_xm_dphi, axis=1)\n",
    "    dot_L     = np.sum(grad_I * d_xm_dL[None, :], axis=1)\n",
    "    \n",
    "    # Compute the gradient of the objective function with respect to each parameter.\n",
    "    # df/dp = - (2/N) * sum_i [ d_i * (grad_I dot (dx_m/dp)) ]\n",
    "    grad_theta = - (2.0 / N) * np.sum(d * dot_theta)\n",
    "    grad_phi   = - (2.0 / N) * np.sum(d * dot_phi)\n",
    "    grad_L     = - (2.0 / N) * np.sum(d * dot_L)\n",
    "    \n",
    "    return np.array([grad_theta, grad_phi, grad_L])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_initialization_2d(bone: np.ndarray,\n",
    "                            image: np.ndarray,\n",
    "                            theta_deg: float,\n",
    "                            phi_deg: float,\n",
    "                            output_path: str,\n",
    "                            pat: str,\n",
    "                            interpolator_intensity,  # RegularGridInterpolator for intensity\n",
    "                            interpolators_gradient: dict,\n",
    "                            plot: bool = True) -> tuple:\n",
    "    \"\"\"\n",
    "    Initializes parameters for plane fitting on a given 3D image using a grid search.\n",
    "    \n",
    "    This function calculates the center of mass (COM) of the input image (or body, if provided)\n",
    "    and uses it to initialize candidate plane parameters. For each candidate plane, it computes\n",
    "    the mean squared error (MSE) between the image and its mirror (using the compute_objective function)\n",
    "    and selects the plane with the lowest MSE.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bone : np.ndarray\n",
    "        The thresholded 3D intensity image for bone.\n",
    "    image_plot : np.ndarray\n",
    "        A 3D image used to compute the center of mass.\n",
    "    output_path : str\n",
    "        Directory in which the MSE heatmap and candidate plane parameters are saved.\n",
    "    pat : str\n",
    "        Patient identifier used for naming output files.\n",
    "    interpolator_intensity : RegularGridInterpolator\n",
    "        Interpolator to evaluate the image intensity at arbitrary (x,y,z) coordinates.\n",
    "    interpolators_gradient : dict\n",
    "        Dictionary with keys 'x', 'y', and 'z' containing RegularGridInterpolator objects\n",
    "        for the corresponding image gradient components.\n",
    "    plot : bool, optional\n",
    "        If True, plots the MSE heatmap. Default is True.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    best_plane_params : tuple\n",
    "        The best plane parameters in the form (a, b, c, D) of the plane equation.\n",
    "    \"\"\"\n",
    "    print(\"Starting initialization...\")\n",
    "    start_initialization = time.time()\n",
    "\n",
    "    # Compute the center of mass (COM) using image_plot.\n",
    "    com = center_of_mass(image)\n",
    "    com = np.array([com[1], com[0], com[2]])  # Adjust COM to match image axes.\n",
    "    \n",
    "    # Define angular search ranges (in radians)\n",
    "    angle_rad_theta = np.deg2rad(theta_deg)\n",
    "    angle_rad_phi = np.deg2rad(phi_deg)\n",
    "    thetas = np.linspace(-angle_rad_theta, angle_rad_theta, 10)  # Candidate polar angles.\n",
    "    phis = np.linspace(-angle_rad_phi, angle_rad_phi, 10)         # Candidate azimuthal angles.\n",
    "    \n",
    "    mse_list = []\n",
    "    mse_data = []\n",
    "    plane_params_list = []\n",
    "\n",
    "    # Use a reference vector (along the x-axis, using image center) to generate candidate normals.\n",
    "    middle_x = image.shape[0] // 2\n",
    "    param_vec = np.array([1, 0, 0])\n",
    "    \n",
    "    # Ensure the output directory exists.\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    mse_array_file = os.path.join(output_path, f\"Initialization_obj_fun.npy\")\n",
    "    plane_params_file = os.path.join(output_path, f\"Initialization_plane_params.npy\")\n",
    "    \n",
    "    # If the files do not exist, compute the grid search.\n",
    "    if not (os.path.exists(mse_array_file) and os.path.exists(plane_params_file)):\n",
    "        for phi_val in phis:\n",
    "            for theta_val in thetas:\n",
    "                # Build the rotation matrix for given theta and phi.\n",
    "                rotation_matrix = np.array([\n",
    "                    [np.cos(theta_val)*np.cos(phi_val), -np.sin(theta_val), np.cos(theta_val)*np.sin(phi_val)],\n",
    "                    [np.sin(theta_val)*np.cos(phi_val),  np.cos(theta_val), np.sin(theta_val)*np.sin(phi_val)],\n",
    "                    [-np.sin(phi_val),                   0,                np.cos(phi_val)]\n",
    "                ])\n",
    "                \n",
    "                # Rotate the reference vector to obtain the candidate normal vector.\n",
    "                rotated_normal_vector = rotation_matrix.dot(param_vec)\n",
    "                D = -np.dot(rotated_normal_vector, com)\n",
    "                rotated_normal_vector = np.abs(D) * rotated_normal_vector\n",
    "                theta_sph, phi_sph, l = vector_to_angles(rotated_normal_vector)\n",
    "\n",
    "                # Save plane parameters (a, b, c, D).\n",
    "                plane_params = np.array([theta_sph, phi_sph, l])\n",
    "                plane_params_list.append(plane_params)\n",
    "                \n",
    "                # Convert the rotated normal vector to spherical coordinates.\n",
    "                # vector_to_angles should return (theta, phi, L) such that L corresponds to the offset.\n",
    "                \n",
    "                \n",
    "                # Compute the MSE for this candidate plane using compute_objective.\n",
    "                mse = compute_objective(plane_params, bone, interpolator_intensity, interpolators_gradient)\n",
    "                mse_list.append(mse)\n",
    "        \n",
    "        mse_array = np.array(mse_list).reshape(len(phis), len(thetas))\n",
    "        plane_params_array = np.array(plane_params_list)\n",
    "        np.save(mse_array_file, mse_array)\n",
    "        np.save(plane_params_file, plane_params_array)\n",
    "    else:\n",
    "        mse_array = np.load(mse_array_file)\n",
    "        mse_list = mse_array.flatten().tolist()\n",
    "        plane_params_array = np.load(plane_params_file)\n",
    "        plane_params_list = plane_params_array.tolist()\n",
    "    \n",
    "    # Plot the MSE heatmap if requested.\n",
    "    if plot:\n",
    "        vmin = np.min(mse_array)\n",
    "        vmax_initial = vmin + 1e7  # Adjust this value if needed.\n",
    "        min_index = np.unravel_index(np.argmin(mse_array), mse_array.shape)\n",
    "        min_phi = np.rad2deg(phis[min_index[0]])\n",
    "        min_theta = np.rad2deg(thetas[min_index[1]])\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(mse_array, extent=[np.rad2deg(thetas[0]), np.rad2deg(thetas[-1]),\n",
    "                                      np.rad2deg(phis[0]), np.rad2deg(phis[-1])],\n",
    "                   aspect='auto', origin='lower', cmap='viridis', vmin=vmin, vmax=vmax_initial)\n",
    "        plt.colorbar(label='Mean Squared Error')\n",
    "        plt.title('MSE vs. Polar and Azimuthal Angles')\n",
    "        plt.xlabel('Polar Angle (Œ∏)¬∞')\n",
    "        plt.ylabel('Azimuthal Angle (œÜ)¬∞')\n",
    "        plt.scatter(min_theta, min_phi, color='red', marker='x', s=100, label='Min MSE')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    #plot_middle_slice_with_planes(image, plane_params_list, title = 'Candidate Planes', output_path = output_path, filename = f'candidate_planes_patient_{pat}.svg')\n",
    "\n",
    "    best_plane_index = np.argmin(mse_list)\n",
    "    best_plane_params = plane_params_list[best_plane_index]\n",
    "    best_plane_params_deg = np.array(np.rad2deg(best_plane_params))\n",
    "    # print(f\"Best plane parameters: {best_plane_params_deg}\")\n",
    "    # print(f\"Best MSE: {mse_list[best_plane_index]}\")\n",
    "    \n",
    "    end_initialization = time.time()\n",
    "    print(f\"Time taken for initialization: {end_initialization - start_initialization:.2f} seconds\")\n",
    "    \n",
    "    return best_plane_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_plane(initial_params_array, image, interpolator_intensity, interpolators_gradient):\n",
    "    \"\"\"\n",
    "    Optimize the plane parameters [theta, phi, L] using the BFGS method.\n",
    "\n",
    "    The objective function is:\n",
    "      f(theta, phi, L) = (1/N) * sum_i [ I(x_i) - I(x_m,i) ]^2,\n",
    "    where x_m is computed as:\n",
    "      x_m = x - 2 * alpha * n,\n",
    "    with\n",
    "      n = [cos(phi)*cos(theta), cos(phi)*sin(theta), sin(phi)]\n",
    "      alpha = cos(phi)*cos(theta)*x + cos(phi)*sin(theta)*y + sin(phi)*z - L.\n",
    "    The voxel coordinates x are taken as the nonzero indices of the image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    initial_params_array : array-like, shape (3,)\n",
    "        Initial guess for the parameters [theta, phi, L].\n",
    "    image : 3D numpy array\n",
    "        The intensity image.\n",
    "    interpolator_intensity : RegularGridInterpolator\n",
    "        Interpolator to evaluate the intensity at any (x, y, z) position.\n",
    "    interpolators_gradient : dict\n",
    "        Dictionary with keys 'x', 'y', and 'z' containing RegularGridInterpolator\n",
    "        objects for the gradient components of the image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res : OptimizeResult\n",
    "        The optimization result returned by scipy.optimize.minimize.\n",
    "        The lists `res.objective_value_list` and `res.params_list` contain the\n",
    "        objective function values and parameter vectors encountered during the optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    # Lists to store the objective values and parameters at each iteration.\n",
    "    objective_value_list = []\n",
    "    params_list = []\n",
    "\n",
    "    # Callback function to save current parameter vector and objective value.\n",
    "    def callback(xk):\n",
    "        # Compute current objective value using our objective function.\n",
    "        f_val = compute_objective(xk, image, interpolator_intensity, interpolators_gradient)\n",
    "        objective_value_list.append(f_val)\n",
    "        params_list.append(xk.copy())\n",
    "\n",
    "    \n",
    "    # Run the optimizer using BFGS.\n",
    "    res = minimize(compute_objective, x0=initial_params_array, args=(image, interpolator_intensity, interpolators_gradient),\n",
    "                   method='BFGS', jac=None, callback=callback)\n",
    "    params_list.append(res.x.copy())\n",
    "    objective_value_list.append(res.fun)\n",
    "\n",
    "    # Attach the objective and parameter histories to the result.\n",
    "    res.objective_value_list = objective_value_list\n",
    "    res.params_list = params_list\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_middle_slice_with_planes(image_data, plane_params_list, title='Middle Slice with Plane Projections', com=None, output_path=None, filename=\"middle_slice_with_planes.svg\"):\n",
    "    \"\"\"\n",
    "    Plot the middle axial slice of a 3D image with projections of multiple planes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_data : numpy.ndarray\n",
    "        The 3D image data.\n",
    "    plane_params_list : list\n",
    "        A list of plane parameters, where each element is a tuple or array of [theta, phi, L].\n",
    "    title : str, optional\n",
    "        The title of the plot.\n",
    "    com : array-like, optional\n",
    "        The center of mass (as [x, y]) to be plotted.\n",
    "    output_path : str, optional\n",
    "        Directory in which to save the figure. If None, the figure is not saved.\n",
    "    filename : str, optional\n",
    "        Filename for the saved figure.\n",
    "    \"\"\"\n",
    "    # Compute the index for the middle axial slice.\n",
    "    middle_slice_index = image_data.shape[2] // 2\n",
    "    slice_array = image_data[:, :, middle_slice_index]\n",
    "    \n",
    "    # Create the figure and axis.\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(slice_array, cmap='gray')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"x (pixels)\")\n",
    "    ax.set_ylabel(\"y (pixels)\")\n",
    "    \n",
    "    # Plot the center of mass if provided.\n",
    "    if com is not None:\n",
    "        ax.scatter(com[0], com[1], color='blue', marker='x', s=100, label='Center of Mass')\n",
    "    \n",
    "    # Create a grid for contour plotting.\n",
    "    ny, nx = slice_array.shape\n",
    "    x = np.linspace(0, nx, 100)\n",
    "    y = np.linspace(0, ny, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # For each plane, compute its intersection with the middle slice.\n",
    "    for plane_coeffs in plane_params_list:\n",
    "        theta, phi, L = plane_coeffs[0], plane_coeffs[1], plane_coeffs[2]\n",
    "        A, B, C = angles_to_vector(theta, phi, L)\n",
    "        D = - np.dot([A, B, C], [A, B, C])\n",
    "        # Normalize the plane coefficients (make a copy so as not to modify the input)\n",
    "\n",
    "        if np.abs(C) < 1e-8:\n",
    "            C = 1e-8\n",
    "        # Solve for z in the plane equation: z = (-A*x - B*y - D) / C.\n",
    "        # Find the contour where z equals the middle slice index.\n",
    "        contour = (-A * X - B * Y - D) / C\n",
    "        ax.contour(X, Y, contour, levels=[middle_slice_index], colors='red')\n",
    "    \n",
    "    if com is not None:\n",
    "        ax.legend()\n",
    "\n",
    "    # Save the figure if an output path is provided.\n",
    "    if output_path is not None:\n",
    "        save_path = os.path.join(output_path, filename)\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Figure saved to {save_path}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrollable Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_points(coords, distances, n_points):\n",
    "    \"\"\"\n",
    "    Randomly sample a subset of points from the coordinate array and their corresponding distances.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coords : numpy.ndarray\n",
    "        A 2D array of shape (N, 3) (or any shape where the first dimension is the number of points)\n",
    "        containing the positions of the voxels.\n",
    "    distances : numpy.ndarray\n",
    "        A 1D array of length N containing the corresponding signed distances.\n",
    "    n_points : int\n",
    "        The number of random points to sample.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    sampled_coords : numpy.ndarray\n",
    "        A 2D array containing the randomly sampled coordinates.\n",
    "    sampled_distances : numpy.ndarray\n",
    "        A 1D array containing the distances corresponding to the sampled coordinates.\n",
    "    \"\"\"\n",
    "    if n_points > len(distances):\n",
    "        n_points = len(distances)\n",
    "    # Randomly select n_points indices from the available points.\n",
    "    indices = np.random.choice(len(distances), size=n_points, replace=False)\n",
    "    sampled_coords = coords[indices]\n",
    "    sampled_distances = distances[indices]\n",
    "    return sampled_coords, sampled_distances\n",
    "\n",
    "def display_scrollable_slices_with_plane(image, gtv_mask, body_mask=None, mandible_mask=None, spinal_cord_mask=None,\n",
    "                              plane_coeffs_list=[], optimization_methods_list=[], points = None, distances = None):\n",
    "    \"\"\"\n",
    "    Display an interactive widget to scroll through slices of the 3D image (in two views) with\n",
    "    overlays of masks and plane contours.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        The 3D image data.\n",
    "    gtv_mask : numpy.ndarray\n",
    "        The 3D primary GTV mask (mandatory).\n",
    "    body_mask : numpy.ndarray, optional\n",
    "        The 3D body mask.\n",
    "    mandible_mask : numpy.ndarray, optional\n",
    "        The 3D mandible mask.\n",
    "    spinal_cord_mask : numpy.ndarray, optional\n",
    "        The 3D spinal cord mask.\n",
    "    plane_coeffs_list : list\n",
    "        List of plane coefficients, where each is a tuple/list (theta, phi, L).\n",
    "    optimization_methods_list : list\n",
    "        List of method names corresponding to each plane, used for the legend.\n",
    "    \"\"\"\n",
    "    num_slices = image.shape[2]\n",
    "    plane_colors = ['red', 'purple', 'cyan']\n",
    "    \n",
    "    # Calculate center of mass from body_mask if provided.\n",
    "    if body_mask is not None:\n",
    "        com = center_of_mass(body_mask)\n",
    "        # Swap first two coordinates to match image orientation.\n",
    "        com = (com[1], com[0], com[2])\n",
    "    else:\n",
    "        com = None\n",
    "    #points, distances = sample_random_points(points, distances, 15)\n",
    "\n",
    "    def view_slice_axial(slice_index):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        # Display the grayscale image.\n",
    "        ax.imshow(image[:, :, slice_index], cmap='gray', interpolation='none')\n",
    "        \n",
    "        if points is not None:\n",
    "            mask = points[:, 2] == slice_index\n",
    "            filtered_coords = points[mask]\n",
    "            filtered_distances = distances[mask]\n",
    "            for (x, y, z), dist in zip(filtered_coords, filtered_distances):\n",
    "                plt.plot(x, y, 'ro', markersize=2)\n",
    "                plt.text(x, y, f\"{round(dist,1)}\", color='green', fontsize=6)\n",
    "                \n",
    "        # Overlay the mandatory GTV mask.\n",
    "        ax.contour(gtv_mask[:, :, slice_index], colors='yellow', linewidths=1)\n",
    "        \n",
    "        # Overlay optional masks if available.\n",
    "        if body_mask is not None:\n",
    "            ax.contour(body_mask[:, :, slice_index], colors='orange', linewidths=1)\n",
    "        if mandible_mask is not None:\n",
    "            ax.contour(mandible_mask[:, :, slice_index], colors='blue', linewidths=1)\n",
    "        if spinal_cord_mask is not None:\n",
    "            ax.contour(spinal_cord_mask[:, :, slice_index], colors='green', linewidths=1)\n",
    "            \n",
    "        # Overlay each plane contour.\n",
    "        for idx, coeffs in enumerate(plane_coeffs_list):\n",
    "            A, B, C = angles_to_vector(coeffs[0], coeffs[1], coeffs[2])\n",
    "            D = - np.dot([A, B, C], [A, B, C])\n",
    "            # Avoid division by zero.\n",
    "            C_val = C if C != 0 else 1e-6\n",
    "            x = np.linspace(0, image.shape[1], 100)\n",
    "            y = np.linspace(0, image.shape[0], 100)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            contour = (-A * X - B * Y - D) / C_val\n",
    "            ax.contour(X, Y, contour, levels=[slice_index],\n",
    "                       colors=plane_colors[idx % len(plane_colors)], linewidths=1)\n",
    "        \n",
    "        # Build legend based on available overlays.\n",
    "        legend_handles = [Line2D([0], [0], color='yellow', lw=2, label='GTVp')]\n",
    "        if body_mask is not None:\n",
    "            legend_handles.append(Line2D([0], [0], color='orange', lw=2, label='Body'))\n",
    "        if mandible_mask is not None:\n",
    "            legend_handles.append(Line2D([0], [0], color='blue', lw=2, label='Mandible'))\n",
    "        if spinal_cord_mask is not None:\n",
    "            legend_handles.append(Line2D([0], [0], color='green', lw=2, label='Spinal Cord'))\n",
    "        for idx, coeffs in enumerate(plane_coeffs_list):\n",
    "            if idx < len(optimization_methods_list):\n",
    "                legend_handles.append(Line2D([0], [0], color=plane_colors[idx % len(plane_colors)],\n",
    "                                              lw=2, label=optimization_methods_list[idx]))\n",
    "        \n",
    "        ax.legend(handles=legend_handles, loc='upper right')\n",
    "        \n",
    "        # Custom coordinate formatter for axial view.\n",
    "        def format_coord(x, y):\n",
    "            col = int(round(x))\n",
    "            row = int(round(y))\n",
    "            info = f\"x={col}, y={row}, slice={slice_index}\"\n",
    "            if 0 <= row < gtv_mask.shape[0] and 0 <= col < gtv_mask.shape[1]:\n",
    "                info += f\", GTVp={gtv_mask[row, col, slice_index]}\"\n",
    "            if body_mask is not None and 0 <= row < body_mask.shape[0] and 0 <= col < body_mask.shape[1]:\n",
    "                info += f\", Body={body_mask[row, col, slice_index]}\"\n",
    "            if mandible_mask is not None and 0 <= row < mandible_mask.shape[0] and 0 <= col < mandible_mask.shape[1]:\n",
    "                info += f\", Mandible={mandible_mask[row, col, slice_index]}\"\n",
    "            if spinal_cord_mask is not None and 0 <= row < spinal_cord_mask.shape[0] and 0 <= col < spinal_cord_mask.shape[1]:\n",
    "                info += f\", Spinal Cord={spinal_cord_mask[row, col, slice_index]}\"\n",
    "            return info\n",
    "        ax.format_coord = format_coord\n",
    "        \n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    # For coronal view, determine slice range along x direction.\n",
    "    if body_mask is not None:\n",
    "        start_slice, end_slice = get_nonzero_slice_range(body_mask, slice_dir_indx=0)\n",
    "    else:\n",
    "        start_slice = 0\n",
    "        end_slice = image.shape[0] - 1\n",
    "\n",
    "    def view_slice_coronal(slice_index):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        # Display coronal view (slice along x axis).\n",
    "        ax.imshow(image[slice_index, :, :], cmap='gray', interpolation='none')\n",
    "        ax.contour(gtv_mask[slice_index, :, :], colors='yellow')\n",
    "        if body_mask is not None:\n",
    "            ax.contour(body_mask[slice_index, :, :], colors='orange')\n",
    "        if mandible_mask is not None:\n",
    "            ax.contour(mandible_mask[slice_index, :, :], colors='blue')\n",
    "        if spinal_cord_mask is not None:\n",
    "            ax.contour(spinal_cord_mask[slice_index, :, :], colors='green')\n",
    "        \n",
    "        for idx, coeffs in enumerate(plane_coeffs_list):\n",
    "            A, B, C = angles_to_vector(coeffs[0], coeffs[1], coeffs[2])\n",
    "            D = - np.dot([A, B, C], [A, B, C])\n",
    "            B_val = B if B != 0 else 1e-6\n",
    "            x = np.linspace(0, image.shape[0], 100)\n",
    "            z = np.linspace(0, image.shape[2], 100)\n",
    "            X, Z = np.meshgrid(x, z)\n",
    "            contour = (-A * X - C * Z - D) / B_val\n",
    "            ax.contour(Z, X, contour, levels=[slice_index], colors=plane_colors[idx % len(plane_colors)])\n",
    "        \n",
    "        # Build legend for coronal view.\n",
    "        # legend_handles = [Line2D([0], [0], color='yellow', lw=2, label='GTVp')]\n",
    "        # if body_mask is not None:\n",
    "        #     legend_handles.append(Line2D([0], [0], color='orange', lw=2, label='Body'))\n",
    "        # if mandible_mask is not None:\n",
    "        #     legend_handles.append(Line2D([0], [0], color='blue', lw=2, label='Mandible'))\n",
    "        # if spinal_cord_mask is not None:\n",
    "        #     legend_handles.append(Line2D([0], [0], color='green', lw=2, label='Spinal Cord'))\n",
    "        # for idx, coeffs in enumerate(plane_coeffs_list):\n",
    "        #     if idx < len(optimization_methods_list):\n",
    "        #         legend_handles.append(Line2D([0], [0], color=plane_colors[idx % len(plane_colors)], lw=2,\n",
    "        #                                       label=optimization_methods_list[idx]))\n",
    "        # ax.legend(handles=legend_handles, loc='upper right')\n",
    "        \n",
    "        ax.set_ylim(start_slice, end_slice)\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    # Interactive slider for axial (z) view.\n",
    "    slice_slider_axial = widgets.IntSlider(min=0, max=num_slices-1, step=1, value=num_slices//2, description='Axial Slice')\n",
    "    display(widgets.interact(view_slice_axial, slice_index=slice_slider_axial))\n",
    "    \n",
    "    # Interactive slider for coronal (x) view.\n",
    "    slice_slider_coronal = widgets.IntSlider(min=start_slice, max=end_slice, step=1, value=(start_slice+end_slice)//2, description='Coronal Slice')\n",
    "    display(widgets.interact(view_slice_coronal, slice_index=slice_slider_coronal))\n",
    "\n",
    "def display_patient_overlay_structures(struct_dict, title=\"Overlay Structures\"):\n",
    "    \"\"\"\n",
    "    Creates an interactive widget that overlays structure contours over the main image.\n",
    "    \n",
    "    The main image is expected under the key \"Image\" and the primary GTV mask under \"GTVp\" in struct_dict.\n",
    "    Other masks (e.g. \"Body\", \"Mandible\", \"Spinal Cord\") are optional. For each slice, the main image is\n",
    "    displayed in grayscale and the available masks are overlaid as contours using predetermined colors.\n",
    "    A legend is added for the masks that are present and a custom coordinate formatter shows the pixel \n",
    "    coordinates and the mask values when hovering over the image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    struct_dict : dict\n",
    "        Dictionary mapping structure names to (image_array, voxel_size).\n",
    "        Must contain keys \"Image\" and \"GTVp\".\n",
    "    title : str, optional\n",
    "        Title prefix for the displayed plot.\n",
    "    \"\"\"\n",
    "    # Check that mandatory keys exist.\n",
    "    if \"Image\" not in struct_dict:\n",
    "        print(\"Main image (key 'Image') not found in the structure dictionary.\")\n",
    "        return\n",
    "    if \"GTVp\" not in struct_dict:\n",
    "        print(\"Primary GTV mask (key 'GTVp') not found in the structure dictionary.\")\n",
    "        return\n",
    "    \n",
    "    main_img, _ = struct_dict[\"Image\"]\n",
    "    gtv_img, _  = struct_dict[\"GTVp\"]\n",
    "    num_slices = main_img.shape[2]\n",
    "    \n",
    "    # Define a dictionary of colors for each structure.\n",
    "    mask_colors = {\n",
    "        \"GTVp\": \"yellow\",   # mandatory\n",
    "        \"Body\": \"red\",\n",
    "        \"Mandible\": \"blue\",\n",
    "        \"Spinal Cord\": \"green\"\n",
    "    }\n",
    "    \n",
    "    # Build list of optional mask keys that are present.\n",
    "    optional_keys = []\n",
    "    for key in [\"Body\", \"Mandible\", \"Spinal Cord\"]:\n",
    "        if key in struct_dict and struct_dict[key] is not None:\n",
    "            optional_keys.append(key)\n",
    "    \n",
    "    def view_slice(slice_index):\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "        # Display the main image in grayscale.\n",
    "        ax.imshow(main_img[:, :, slice_index], cmap='gray', interpolation='none')\n",
    "        \n",
    "        # Overlay the mandatory GTV mask.\n",
    "        ax.contour(gtv_img[:, :, slice_index], levels=[0.5], colors=mask_colors[\"GTVp\"], linewidths=2)\n",
    "        \n",
    "        # Overlay optional masks if available.\n",
    "        for key in optional_keys:\n",
    "            mask_img, _ = struct_dict[key]\n",
    "            # Only add the contour if there is any nonzero element.\n",
    "            if np.any(mask_img[:, :, slice_index]):\n",
    "                ax.contour(mask_img[:, :, slice_index], levels=[0.5], colors=mask_colors[key], linewidths=2)\n",
    "        \n",
    "        # Build legend using dummy handles.\n",
    "        legend_handles = [Line2D([0], [0], color=mask_colors[\"GTVp\"], lw=2, label=\"GTVp\")]\n",
    "        for key in optional_keys:\n",
    "            legend_handles.append(Line2D([0], [0], color=mask_colors[key], lw=2, label=key))\n",
    "        ax.legend(handles=legend_handles, loc='upper right')\n",
    "        \n",
    "        # # Set a custom coordinate formatter.\n",
    "        # def format_coord(x, y):\n",
    "        #     col = int(round(x))\n",
    "        #     row = int(round(y))\n",
    "        #     info = f\"x={col}, y={row}, slice={slice_index}\"\n",
    "        #     # Always show value from GTVp.\n",
    "        #     if 0 <= row < gtv_img.shape[0] and 0 <= col < gtv_img.shape[1]:\n",
    "        #         info += f\", GTVp={gtv_img[row, col, slice_index]}\"\n",
    "        #     # Append info for each optional mask.\n",
    "        #     for key in optional_keys:\n",
    "        #         mask_img, _ = struct_dict[key]\n",
    "        #         if 0 <= row < mask_img.shape[0] and 0 <= col < mask_img.shape[1]:\n",
    "        #             info += f\", {key}={mask_img[row, col, slice_index]}\"\n",
    "        #     return info\n",
    "        # ax.format_coord = format_coord\n",
    "        \n",
    "        ax.set_title(f\"{title} - Slice {slice_index}\")\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    slider = widgets.IntSlider(min=0, max=num_slices-1, step=1, value=num_slices//2, description='Slice')\n",
    "    display(widgets.interact(view_slice, slice_index=slider))\n",
    "\n",
    "def process_all_patient_folders(root_folder, patterns, display_widgets=True):\n",
    "    \"\"\"\n",
    "    Loop over all patient folders in the given root_folder and process each one.\n",
    "    \n",
    "    For each patient folder (assumed to be named with a patient ID), the function:\n",
    "      - Loads the main image and structure mask files using the provided regex patterns,\n",
    "        transposing each array with np.transpose(array, (1,0,2)).\n",
    "      - Creates an interactive widget that overlays the structure contours over the main image,\n",
    "        allowing scrolling through the slices along axis 2.\n",
    "      - Stores the loaded data in a dictionary keyed by patient ID.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    root_folder : str\n",
    "        Directory containing patient folders (each named with a patient ID).\n",
    "    patterns : dict\n",
    "        Dictionary mapping structure names (e.g., \"image\", \"gtvp\", etc.) to regex patterns.\n",
    "    display_widgets : bool, optional\n",
    "        If True, display the interactive widget for each patient (default True).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary mapping each patient ID (folder name) to a dictionary with keys:\n",
    "          - \"image\": the transposed main image (3D numpy array),\n",
    "          - \"voxel_size\": the voxel dimensions,\n",
    "          - \"masks\": a dictionary mapping mask names to the transposed 3D mask arrays.\n",
    "    \"\"\"\n",
    "    all_patient_data = {}\n",
    "    \n",
    "    # Loop over each item in the root_folder.\n",
    "    for patient_id in sorted(os.listdir(root_folder)):\n",
    "        patient_folder = os.path.join(root_folder, patient_id)\n",
    "        \n",
    "        if os.path.isdir(patient_folder):\n",
    "            print(f\"Processing patient folder: {patient_id}\")\n",
    "            # Load structures from the patient folder using your patterns.\n",
    "            struct_data = load_patient_structures(patient_folder, patterns)\n",
    "            if struct_data:\n",
    "                all_patient_data[patient_id] = struct_data\n",
    "                # Display an interactive overlay widget if requested.\n",
    "                if display_widgets:\n",
    "                    display_patient_overlay_structures(struct_data, title=f\"Patient {patient_id} Overlay\")\n",
    "            else:\n",
    "                print(f\"No matching files found for patient {patient_id}.\")\n",
    "    \n",
    "    return all_patient_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midline_optimized(csv_filepath, base_path, output_path, \n",
    "                      patient=None,\n",
    "                      theta_deg=25, phi_deg=10,\n",
    "                      optimization_method='BFGS', \n",
    "                      results_path_list=None, \n",
    "                      optimization_methods_list=None,\n",
    "                      HU_range=None,\n",
    "                      slice_range=None,\n",
    "                      patient_range=None):\n",
    "                      \n",
    "    \"\"\"\n",
    "    Process patient data from a CSV file, compute and optimize midline plane parameters.\n",
    "    \n",
    "    For each patient, this function:\n",
    "      - Processes patient data and applies appropriate masks.\n",
    "      - Extracts nonzero slices and creates intensity and gradient interpolators.\n",
    "      - Initializes candidate plane parameters using a grid search (via param_initialization_2d).\n",
    "      - Optimizes the plane parameters using optimize_plane (BFGS) if not already saved.\n",
    "      - Optionally displays additional results.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    start_pipeline = time.time()\n",
    "    list_best_plane_params = []\n",
    "    list_obj_fun = []\n",
    "    \n",
    "    df = pd.read_csv(csv_filepath)\n",
    "\n",
    "    if patient is not None:\n",
    "        df = df[df['Patient ID'] == patient].reset_index(drop=True)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        if patient_range is not None:\n",
    "            if idx < patient_range[0]:\n",
    "                continue\n",
    "            if idx > patient_range[1]:\n",
    "                break\n",
    "        pat_id = row['Patient ID']\n",
    "        pat_id = str(pat_id).zfill(8)\n",
    "        if pd.isna(pat_id) or pd.isna(row['GTVp']):\n",
    "            continue\n",
    "        print(f\"Processing patient {pat_id} at CSV row {idx}...\")\n",
    "        \n",
    "        output_path_patient = os.path.join(output_path, f'{pat_id}')\n",
    "        # if os.path.exists(output_path_patient):\n",
    "        #     print(f\"Patient {pat_id} already processed. Skipping...\")\n",
    "        #     continue\n",
    "        \n",
    "        os.makedirs(output_path_patient, exist_ok=True)\n",
    "        \n",
    "        # Load patient data from the selected row.\n",
    "        pdata, pid = load_patient_data_from_row(row, base_path)\n",
    "        if pdata is None or pid is None:\n",
    "            print(f\"Failed to load data for patient at CSV row {idx}.\")\n",
    "            continue\n",
    "        else:\n",
    "            # Extract arrays (each tuple is (array, voxel_size)).\n",
    "            image = pdata.get(\"Image\", (None,))[0]\n",
    "            body = pdata.get(\"Body\", (None,))[0]\n",
    "            gtvp = pdata.get(\"GTVp\", (None,))[0]\n",
    "            if image is None or gtvp is None:\n",
    "                print(f\"Patient {pid} is missing required data. Skipping...\")\n",
    "                continue\n",
    "            mandibula = pdata.get(\"Mandible\", (None,))[0]\n",
    "            spinalcord = pdata.get(\"Spinal Cord\", (None,))[0]\n",
    "            \n",
    "            print(f\"Patient {pid} data loaded successfully.\")\n",
    "        \n",
    "        # display_scrollable_slices_with_plane(image, gtvp, body, mandibula, spinalcord)\n",
    "        # break\n",
    "        # Convert image to int16 to avoid overflow errors.\n",
    "        image = image.astype(np.int16)\n",
    "        \n",
    "        if body is not None:\n",
    "        # Apply binary erosion to the body mask.\n",
    "            body = binary_erosion(body, iterations=2).astype(np.uint8)\n",
    "            \n",
    "            # Mask the image using the body mask (background set to -1000).\n",
    "            image = np.where(body == 1, image, -1000)\n",
    "        \n",
    "        # Create bone mask and compute bone CT.\n",
    "        if HU_range is None:\n",
    "            HU_range = (900, 2500)\n",
    "        bone_mask = mask_via_threshold(image, HU_range=(HU_range)).astype(np.uint16)\n",
    "        bone_ct = image * bone_mask\n",
    "        \n",
    "        # # Process dental fillings: extract mask and assign HU values.\n",
    "        dental_fillings_mask = mask_via_threshold(image, HU_range=(HU_range[1], 5000)).astype(np.uint16)\n",
    "        dental_bone_ct = 1500 * dental_fillings_mask\n",
    "        bone_ct = bone_ct + dental_bone_ct\n",
    "        image = image * (1 - dental_fillings_mask) + dental_bone_ct\n",
    "        \n",
    "        # Extract the nonzero slice range from gtvp and apply to all volumes.\n",
    "        start_slice, end_slice = get_nonzero_slice_range(gtvp)\n",
    "        if slice_range is not None:\n",
    "            start_slice = slice_range[0]\n",
    "            end_slice = slice_range[1] + 1\n",
    "        \n",
    "        image = image[:, :, start_slice:end_slice + 1]\n",
    "        bone_ct = bone_ct[:, :, start_slice:end_slice + 1]\n",
    "        gtvp = gtvp[:, :, start_slice:end_slice + 1]\n",
    "        # For optional structures, only apply slicing if they exist.\n",
    "        if body is not None:\n",
    "            body = body[:, :, start_slice:end_slice + 1]\n",
    "        if mandibula is not None:\n",
    "            mandibula = mandibula[:, :, start_slice:end_slice + 1]\n",
    "        if spinalcord is not None:\n",
    "            spinalcord = spinalcord[:, :, start_slice:end_slice + 1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Attempt to load a saved intensity interpolator; if not, it will be created below.\n",
    "        interpolator_path = os.path.join(output_path_patient, 'interpolator.joblib')\n",
    "        interpolators_gradient_path = os.path.join(output_path_patient, 'interpolators_gradient.joblib')\n",
    "        shape = image.shape\n",
    "        grid_x = np.arange(shape[0])\n",
    "        grid_y = np.arange(shape[1])\n",
    "        grid_z = np.arange(shape[2])\n",
    "\n",
    "        if os.path.exists(interpolator_path):\n",
    "            interpolator = joblib.load(interpolator_path)\n",
    "        else:\n",
    "            start_interpolator = time.time()\n",
    "            interpolator = RegularGridInterpolator((grid_x, grid_y, grid_z), image, \n",
    "                                                   method='cubic', bounds_error=False, fill_value=None)\n",
    "            end_interpolator = time.time()\n",
    "            print(f\"Cubic interpolator took {end_interpolator - start_interpolator:.2f} seconds.\")\n",
    "            joblib.dump(interpolator, interpolator_path)\n",
    "\n",
    "        interpolators_gradient = None\n",
    "        \n",
    "        # if os.path.exists(interpolators_gradient_path):\n",
    "        #     interpolators_gradient = joblib.load(interpolators_gradient_path)\n",
    "        # else:\n",
    "        #     # Create intensity and gradient interpolators.\n",
    "        #     shape = image.shape\n",
    "        #     gradient_x = sobel(image, axis=0)\n",
    "        #     gradient_y = sobel(image, axis=1)\n",
    "        #     gradient_z = sobel(image, axis=2)\n",
    "            \n",
    "        #     interpolators_gradient = {\n",
    "        #         'x': RegularGridInterpolator((grid_x, grid_y, grid_z), gradient_x, \n",
    "        #                                     method='cubic', bounds_error=False, fill_value=None),\n",
    "        #         'y': RegularGridInterpolator((grid_x, grid_y, grid_z), gradient_y, \n",
    "        #                                     method='cubic', bounds_error=False, fill_value=None),\n",
    "        #         'z': RegularGridInterpolator((grid_x, grid_y, grid_z), gradient_z, \n",
    "        #                                     method='cubic', bounds_error=False, fill_value=None)\n",
    "        #     }\n",
    "        #     joblib.dump(interpolators_gradient, interpolators_gradient_path)\n",
    "        \n",
    "        \n",
    "        # Initialize candidate plane parameters using a grid search.\n",
    "        initial_plane = param_initialization_2d(bone_ct, image, theta_deg, phi_deg, output_path_patient, idx, \n",
    "                                                interpolator, interpolators_gradient, plot=False)\n",
    "        \n",
    "        if os.path.exists(os.path.join(output_path_patient, \"params_array.npy\")): \n",
    "            plane_params = np.load(os.path.join(output_path_patient, \"params_array.npy\"))\n",
    "            best_plane_params = plane_params[-1]\n",
    "            #distances, normal_vector, indices_coord, indices_im = compute_signed_distances(best_plane_params, gtvp)\n",
    "            display_scrollable_slices_with_plane(image, gtvp, body, mandibula, spinalcord, [best_plane_params], [optimization_method])\n",
    "            \n",
    "            # second_path = os.path.join(r\"/home/loriskeller/Documents/Master Project/VS/Data_extract_and_midline/Results/results_07_04_25/Midsagplanes_HU300to2500\", f'{pat_id}')\n",
    "            # second_plane_params = np.load(os.path.join(second_path, \"params_array.npy\"))\n",
    "            # second_best_plane_params = second_plane_params[-1]\n",
    "            # display_scrollable_slices_with_plane(image, gtvp, body, mandibula, spinalcord, [best_plane_params,second_best_plane_params], [f\"900-2000\", f\"300-2000\"])\n",
    "        else:\n",
    "            # Optimize the plane parameters using the BFGS method.\n",
    "            start_optimization = time.time()\n",
    "            opt_result = optimize_plane(initial_plane, bone_ct, interpolator, interpolators_gradient)\n",
    "            end_optimization = time.time()\n",
    "            best_plane_params = opt_result.x  # Optimized [theta, phi, L].\n",
    "            obj_fun = opt_result.fun\n",
    "            print(f\"Optimization ({optimization_method}) took {end_optimization - start_optimization:.2f} seconds.\")\n",
    "            print(f\"Optimized parameters: {np.rad2deg(best_plane_params[0])}, {np.rad2deg(best_plane_params[1])}, {best_plane_params[2]} with MSE {round(obj_fun, 2)}\")\n",
    "            best_plane_result = {'params': best_plane_params, 'obj_fun': obj_fun}\n",
    "            # Assuming res is the optimization result from optimize_plane.\n",
    "            params_array = np.array(opt_result.params_list)\n",
    "            objective_array = np.array(opt_result.objective_value_list)\n",
    "            # Save as .npy files.\n",
    "            np.save(os.path.join(output_path_patient, \"params_array.npy\"), params_array)\n",
    "            np.save(os.path.join(output_path_patient, \"objective_array.npy\"), objective_array)\n",
    "\n",
    "            if patient is None:\n",
    "                list_best_plane_params.append(best_plane_params)\n",
    "                list_obj_fun.append(obj_fun)\n",
    "        \n",
    "            # Plot the middle slice with the optimized plane.\n",
    "            #plot_middle_slice_with_planes(image, [best_plane_params], title='Middle Slice with Optimized Plane', output_path=output_path_patient, filename=f'Image_slice_with_plane.svg')\n",
    "            #display_scrollable_slices_with_plane(image, gtvp, body, mandibula, spinalcord, [best_plane_params], [optimization_method])\n",
    "        \n",
    "        # Optionally, display additional results.\n",
    "        # if results_path_list is not None:\n",
    "        #     results_list = [np.load(path) for path in results_path_list]\n",
    "        #     display_scrollable_slices_with_plane(image, body, gtvp, mandibula, spinalcord, results_list, optimization_methods_list)\n",
    "        \n",
    "        \n",
    "    # Suppose list_best_plane_params and list_obj_fun are Python lists containing numeric values or arrays.\n",
    "    # if not os.path.exists(output_path):\n",
    "    #     # Save the results as a compressed .npz file.\n",
    "    #     np.savez_compressed(os.path.join(output_path, \"best_params_and_objectives.npz\"),\n",
    "    #                 best_plane_params=list_best_plane_params,\n",
    "    #                 objective_values=list_obj_fun)\n",
    "        \n",
    "\n",
    "    end_pipeline = time.time()\n",
    "    print(f\"Total time for processing {idx + 1} patients: {end_pipeline - start_pipeline:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping to real space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physical_plane_params(theta, phi, L, voxel_size):\n",
    "    \"\"\"\n",
    "    Convert plane parameters from voxel space to physical space.\n",
    "\n",
    "    Parameters:\n",
    "        theta, phi, L : float\n",
    "                Plane parameters in voxel space.\n",
    "        voxel_size : np.array\n",
    "                Voxel size.\n",
    "\n",
    "    Returns:\n",
    "        params_real : np.array\n",
    "                Plane parameters in physical space.\n",
    "    \"\"\"\n",
    "    \n",
    "    vec_normalized = np.array([np.cos(phi)*np.cos(theta),\n",
    "                    np.cos(phi)*np.sin(theta),\n",
    "                    np.sin(phi)])\n",
    "    vec = L * vec_normalized\n",
    "    vec_real = np.array([vec[0] * voxel_size[0],\n",
    "                         vec[1] * voxel_size[1],\n",
    "                         vec[2] * voxel_size[2]])\n",
    "    theta_real, phi_real, L_real = vector_to_angles(vec_real)\n",
    "    params_real = np.array([theta_real, phi_real, L_real])\n",
    "\n",
    "    return params_real\n",
    "\n",
    "def real_distance_to_plane(x_voxel, theta, phi, L, voxel_size):\n",
    "    \"\"\"\n",
    "    Compute the physical distance (mm) from a set of voxel points to the plane defined by theta, phi, and L.\n",
    "    \n",
    "    Parameters:\n",
    "      x_voxel : np.array of shape (n,3)\n",
    "          The array of voxel coordinates, where each row is [x, y, z].\n",
    "      theta, phi, L : float\n",
    "          Plane parameters in voxel space.\n",
    "      voxel_size : array-like, shape (3,)\n",
    "          Voxel dimensions as [s_x, s_y, s_z].\n",
    "    \n",
    "    Returns:\n",
    "      d : np.array\n",
    "          A 1D array of signed distances (in mm) for each voxel.\n",
    "    \"\"\"\n",
    "    # Convert voxel coordinates to physical coordinates via broadcasting.\n",
    "    x_phys = x_voxel * np.array(voxel_size)  # Each column multiplied by corresponding voxel size.\n",
    "    \n",
    "    # Convert plane parameters to physical space.\n",
    "    theta_real, phi_real, L_real = physical_plane_params(theta, phi, L, voxel_size)\n",
    "    \n",
    "    # Compute signed distance for each voxel.\n",
    "    d = (np.cos(phi_real)*np.cos(theta_real)*x_phys[:, 0] +\n",
    "         np.cos(phi_real)*np.sin(theta_real)*x_phys[:, 1] +\n",
    "         np.sin(phi_real)*x_phys[:, 2] - L_real)\n",
    "    \n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mse_vs_parameters(image, interpolator_intensity, interpolators_gradient,\n",
    "                           theta_best, phi_best, L_best, output_path, pat):\n",
    "    \"\"\"\n",
    "    Generate plots of the mean squared error (MSE) as a function of Œ∏, œÜ, and L.\n",
    "    \n",
    "    For each parameter, a range is defined around the best value and the objective\n",
    "    function is evaluated while holding the other two parameters fixed.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        The 3D image.\n",
    "    interpolator_intensity : RegularGridInterpolator\n",
    "        Interpolator for the image intensity.\n",
    "    interpolators_gradient : dict\n",
    "        Dictionary with keys 'x', 'y', and 'z' containing RegularGridInterpolator \n",
    "        objects for the image gradients.\n",
    "    theta_best : float\n",
    "        Best theta value (in radians).\n",
    "    phi_best : float\n",
    "        Best phi value (in radians).\n",
    "    L_best : float\n",
    "        Best L value.\n",
    "    output_path : str\n",
    "        Directory where the plots will be saved.\n",
    "    pat : str or int\n",
    "        Identifier (e.g. patient number) used in filenames.\n",
    "    \"\"\"\n",
    "    # Define parameter ranges around the best values.\n",
    "    # For theta and phi, use ¬±2 degrees (converted to radians)\n",
    "    delta_rad = np.deg2rad(2)\n",
    "    theta_range = np.linspace(theta_best - delta_rad, theta_best + delta_rad, 100)\n",
    "    phi_range   = np.linspace(phi_best - delta_rad, phi_best + delta_rad, 100)\n",
    "    # For L, use ¬±4 units around L_best.\n",
    "    L_range     = np.linspace(L_best - 4, L_best + 4, 100)\n",
    "    \n",
    "    mse_theta = []\n",
    "    mse_phi   = []\n",
    "    mse_L     = []\n",
    "    \n",
    "    # Compute MSE vs. Theta (with œÜ and L fixed)\n",
    "    for theta in theta_range:\n",
    "        mse = compute_objective(np.array([theta, phi_best, L_best]),\n",
    "                                image, interpolator_intensity, interpolators_gradient)\n",
    "        mse_theta.append(mse)\n",
    "    \n",
    "    # Compute MSE vs. Phi (with Œ∏ and L fixed)\n",
    "    for phi in phi_range:\n",
    "        mse = compute_objective(np.array([theta_best, phi, L_best]),\n",
    "                                image, interpolator_intensity, interpolators_gradient)\n",
    "        mse_phi.append(mse)\n",
    "    \n",
    "    # Compute MSE vs. L (with Œ∏ and œÜ fixed)\n",
    "    for L in L_range:\n",
    "        mse = compute_objective(np.array([theta_best, phi_best, L]),\n",
    "                                image, interpolator_intensity, interpolators_gradient)\n",
    "        mse_L.append(mse)\n",
    "    \n",
    "    # Plot MSE vs. Theta\n",
    "    plt.figure()\n",
    "    plt.plot(np.degrees(theta_range), mse_theta, label='MSE vs. Theta')\n",
    "    plt.xlabel('Theta (degrees)')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE vs. Theta\\nBest Theta = {:.2f}¬∞'.format(np.degrees(theta_best)))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    theta_filename = os.path.join(output_path, f'mse_vs_theta_{pat}.svg')\n",
    "    plt.savefig(theta_filename)\n",
    "    \n",
    "    # Plot MSE vs. Phi\n",
    "    plt.figure()\n",
    "    plt.plot(np.degrees(phi_range), mse_phi, label='MSE vs. Phi')\n",
    "    plt.xlabel('Phi (degrees)')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE vs. Phi\\nBest Phi = {:.2f}¬∞'.format(np.degrees(phi_best)))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    phi_filename = os.path.join(output_path, f'mse_vs_phi_{pat}.svg')\n",
    "    plt.savefig(phi_filename)\n",
    "    \n",
    "    # Plot MSE vs. L\n",
    "    plt.figure()\n",
    "    plt.plot(L_range, mse_L, label='MSE vs. L')\n",
    "    plt.xlabel('L')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE vs. L\\nBest L = {:.2f}'.format(L_best))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    L_filename = os.path.join(output_path, f'mse_vs_L_{pat}.svg')\n",
    "    plt.savefig(L_filename)\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"MSE plots saved successfully:\")\n",
    "    print(f\"  Theta plot: {theta_filename}\")\n",
    "    print(f\"  Phi plot:   {phi_filename}\")\n",
    "    print(f\"  L plot:     {L_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patient 10683066 at CSV row 0...\n",
      "‚úÖ Success: 'temp_nifti.nii' was written successfully (679383904 bytes).\n",
      "‚úÖ Success: 'temp_nifti.nii' was written successfully (679383904 bytes).\n",
      "Loaded GTVp from /home/loriskeller/Documents/Master Project/Patient data/patient_data_complete/Patient_structures_clean/10683066/GTVp.nii.gz\n",
      "‚úÖ Success: 'temp_nifti.nii' was written successfully (679383904 bytes).\n",
      "Loaded Body from /home/loriskeller/Documents/Master Project/Patient data/patient_data_complete/Patient_structures_clean/10683066/mask_BODY.nii.gz\n",
      "‚úÖ Success: 'temp_nifti.nii' was written successfully (679383904 bytes).\n",
      "Loaded Mandible from /home/loriskeller/Documents/Master Project/Patient data/patient_data_complete/Patient_structures_clean/10683066/mask_Mandible.nii.gz\n",
      "‚úÖ Success: 'temp_nifti.nii' was written successfully (679383904 bytes).\n",
      "Loaded Spinal Cord from /home/loriskeller/Documents/Master Project/Patient data/patient_data_complete/Patient_structures_clean/10683066/mask_SpinalCord.nii.gz\n",
      "Patient 10683066 data loaded successfully.\n",
      "Starting initialization...\n",
      "Time taken for initialization: 0.28 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceed0500e9894512932e780c96c7929d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=19, description='Axial Slice', max=38), Output()), _dom_classes=('widget‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display_scrollable_slices_with_plane.<locals>.view_slice_axial(slice_index)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3751d8f247b4bacb98763edbec64f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=270, description='Coronal Slice', max=386, min=155), Output()), _dom_cla‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display_scrollable_slices_with_plane.<locals>.view_slice_coronal(slice_index)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for processing 1 patients: 12.10 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "#%matplotlib inline\n",
    "\n",
    "data_path = r\"/home/loriskeller/Documents/Master Project/Patient data/patient_data_complete/Patient_structures_clean\"\n",
    "csv_path = r\"/home/loriskeller/Documents/Master Project/filtered_patients_extention_position_structures_final.csv\"\n",
    "output_path = r\"/home/loriskeller/Documents/Master Project/VS/Data_extract_and_midline/Results/14.04.25/Midsagittalplanes Huber delta 300, threshold 300-1500\"\n",
    "\n",
    "midline_optimized(csv_path, data_path, output_path, theta_deg=25, phi_deg=10, optimization_method='BFGS', patient = 10683066 , HU_range=(300, 1500), \n",
    "                  slice_range=None, patient_range=None)\n",
    "\n",
    "#load_patient_data_from_csv(csv_path, data_path, pat_id=10161216)\n",
    "\n",
    "# 10687063\n",
    "# 10376522\n",
    "# 10587029\n",
    "# 10027159\n",
    "# 10621910\n",
    "# 10774767\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
